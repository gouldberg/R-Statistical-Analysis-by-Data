# ----------
# simple dummy coding with the auditory condition as baseline
( ctrAudio <- contr.treatment(3) )
# ----------
set.seed(222)
# The authors suggest that the number of projections to be used should be min(30, n)
# Since in our data n = 800, we are good with 30 projections
# fitrpm <- anova.RPm(fdat, ~ cond, gdat, RP = 30, contrast = list(cond = ctrAudio))
fitrpm <- fanova.RPm(fdat, ~ cond, gdat, RP = 30, contrast = list(cond = ctrAudio))
summary.fanova(fitrpm)
summary(fitrpm)
summary(fitrpm)
library(refund)
# We need to convert the data into an fd object and then set up the design matrix
ftension2 <- fdata2fd(ftension1)
X <- model.matrix(~ cond)  ## auditory as baseline
install.packages("refund", dep = T)
library(refund)
# We need to convert the data into an fd object and then set up the design matrix
ftension2 <- fdata2fd(ftension1)
X <- model.matrix(~ cond)  ## auditory as baseline
tenreg <- fosr(fdobj = ftension2, X = X, lambda = 100)
tenreg
# ----------
refund:::plot.fosr(tenreg, titles = c("Intercept", "Auditory vs. Visual", "Auditory vs. Visual-Auditory"))
tenreg
X
cond
X
head(X)
fpca <- fdata2pc(ftension1, ncomp = 2)
# ----------
summary(fpca, biplot = TRUE)
# ------------------------------------------------------------------------------
# functional loadings for each component
# ------------------------------------------------------------------------------
pcscores <- fpca$x[,1:2]
graphics.off()
par(mfrow = c(1,2), mar = c(2,2,2,2))
plot(fpca$rotation[1,]$argvals, fpca$rotation$data[1,], type = "l", ylim = c(-0.3, 0.3), xlab = "Time",  ylab = "Loadings", main = "Functional PCA Loadings", lwd = 2)
lines(fpca$rotation$argvals, fpca$rotation$data[2,], type = "l", col = "gray", lwd = 2)
legend("topright", legend = c("PC1", "PC2"), lty = 1, col = c(1, "gray"), cex = 0.5)
plot(pcscores, type = "n", asp = 1, main = "Functional PC Scores")
cols <- c("black", "coral", "cadetblue")[as.numeric(cond)]
text(pcscores, col = cols)
legend("topright", legend = c("Auditory", "Visual", "Auditory & Visual"), text.col = c("black", "coral", "cadetblue"), cex = 0.5)
fpca <- fdata2pc(ftension1, ncomp = 2)
summary(fpca, biplot = TRUE)
summary(fpca, biplot = TRUE)
biplot(fpca)
summary(fpca)
fpca <- fdata2pc(ftension1, ncomp = 2)
help("summary.fdata.comp")
summary.fdata.comp(fpca, biplot = TRUE)
fpca
sumamry(fpca)
fpca <- fdata2pc(ftension1, ncomp = 2)
summary(fpca, biplot = TRUE)
n= 100;tt= seq(0,1,len=51)
x0<-rproc2fdata(n,tt,sigma="wiener")
x1<-rproc2fdata(n,tt,sigma=0.1)
x<-x0*3+x1
pc=fdata2pc(x,lambda=1)
summary(pc)
pcscores <- fpca$x[,1:2]
graphics.off()
par(mfrow = c(1,2), mar = c(2,2,2,2))
plot(fpca$rotation[1,]$argvals, fpca$rotation$data[1,], type = "l", ylim = c(-0.3, 0.3), xlab = "Time",  ylab = "Loadings", main = "Functional PCA Loadings", lwd = 2)
lines(fpca$rotation$argvals, fpca$rotation$data[2,], type = "l", col = "gray", lwd = 2)
legend("topright", legend = c("PC1", "PC2"), lty = 1, col = c(1, "gray"), cex = 0.5)
plot(pcscores, type = "n", asp = 1, main = "Functional PC Scores")
cols <- c("black", "coral", "cadetblue")[as.numeric(cond)]
text(pcscores, col = cols)
legend("topright", legend = c("Auditory", "Visual", "Auditory & Visual"), text.col = c("black", "coral", "cadetblue"), cex = 0.5)
graphics.off()
par(mfrow = c(2, 2), mar = c(2,2,2,2))
plot(ftensionNP$fdata.est[c(19)], main = "middle", col = c(1))
plot(ftensionNP$fdata.est[c(14,18)], main = "Positive Comp 1", col = c(1:2))
plot(ftensionNP$fdata.est[c(10)], main = "Negatice Comp 1", col = c(1))
plot(ftensionNP$fdata.est[c(17)], main = "positive Comp 2", col = c(1))
fmean <- func.mean(ftension1)
# Note that the multiple of 3 is arbitrary.
pc1plus <- fmean$data[1,] + 3 * fpca$rotation$data[1,]
pc1minus <- fmean$data[1,] - 3 * fpca$rotation$data[1,]
pc2plus <- fmean$data[1,] + 3 * fpca$rotation$data[2,]
pc2minus <- fmean$data[1,] - 3 * fpca$rotation$data[2,]
# ----------
graphics.off()
par(mfrow = c(1,2), mar = c(2,2,2,2))
plot(fmean, lwd = 2, main = "Mean (PC1)", ylim = c(-2, 2))
lines(ftension1$argvals, pc1plus, col = "red")
lines(ftension1$argvals, pc1minus, col = "blue")
legend("bottomright", legend = c("mean + PC1", "mean - PC1"), lty = 1, col = c("red", "blue"))
plot(fmean, lwd = 2, main = "Mean (PC2)", ylim = c(-2, 2))
lines(ftension1$argvals, pc2plus, col = "red")
lines(ftension1$argvals, pc2minus, col = "blue")
legend("bottomright", legend = c("mean + PC2", "mean - PC2"), lty = 1, col = c("red", "blue"))
rm(list=ls)
rm(list=ls())
graphics.off()
data(cmort, package = "astsa")
str(cmort)
cmort
data(cmort, package = "astsa")
data(tempr, package = "astsa")
data(part, package = "astsa")
str(cmort)
str(tempr)
str(part)
cmort
tempr
part
par(mfrow = c(3,1))
plot(cmort, main = "Cardiovascular Mortality", xlab = "", ylab = "")
plot(tempr, main = "Temerature", xlab = "", ylab = "")
plot(part, main = "Particulates", xlab = "", ylab = "")
pairs(cbind(Mortality = cmort, Temperature = tempr,  Particulates = part))
psych::pairs.panels(cbind(Mortality = cmort, Temperature = tempr,  Particulates = part))
plot(tempr, cmort, xlab = "Temperature", ylab = "Mortality", pch = 20, col = gray(0.7))
lines(lowess(tempr, cmort), col = "blue")
par(mfrow = c(1,1))
plot(tempr, cmort, xlab = "Temperature", ylab = "Mortality", pch = 20, col = gray(0.7))
lines(lowess(tempr, cmort), col = "blue")
# Mt:  cardiovascular mortality
# Tt:  temperature
# Pt:  particulate levels
temp <- tempr - mean(tempr)
temp2 <- temp ^ 2
trend <- time(cmort)
# Here we use of na.action in lm() is to retain the time series attributes for the residuals and fitted values
# ----------
# trend only model:  Mt = beta0 + beta1 * t + wt
fit1 <- lm(cmort ~ trend, na.action = NULL)
summary(fit1)
# liniear temperature:  Mt = beta0 + beta1 * t + beta2 * (Tt - T.) + wt
fit2 <- lm(cmort ~ trend + temp, na.action = NULL)
summary(fit1)
summary(fit2)
# -->
# As expected, a negative trend is present in time as well as a negative coefficient for adjusted temperature.
# ----------
# curvilinear temperature:  Mt = beta0 + beta1 * t + beta2 * (Tt - T.) + beta3 * (Tt - T.)^2 + wt
fit3 <- lm(cmort ~ trend + temp + temp2, na.action = NULL)
# -->
# The quadratic effect of temperature can clearly be seen in the scatterplots
# ----------
# curvilinear temperature and pollution:  Mt = beta0 + beta1 * t + beta2 * (Tt - T.) + beta3 * (Tt - T.)^2 + beta4 * Pt + wt
fit4 <- lm(cmort ~ trend + temp + temp2 + part, na.action = NULL)
library(stargazer)
stargazer(fit1, fit2, fit3, fit4, type = "text")
AIC(fit1, fit2, fit3, fit4, k = log(length(cmort)))
# -->
summary(fit4)
summary(aov(fit4))
drop1(fit4)
num <- length(cmort)
AIC(fit4) / num - log(2 * pi)
BIC(fit4) / num - log(2 * pi)
log(sum(resid(fit4) ^ 2) / num) + (num + 5) / (num - 5 - 2)
# ----------
summary(aov(fit4))
drop1(fit4)
par(mfrow = c(3,1))
forecast::Acf(diff(cmort), lag.max = 50, plot=TRUE)
forecast::Acf(diff(tempr), lag.max = 50, plot=TRUE)
forecast::Acf(diff(part), lag.max = 50, plot=TRUE)
par(mfrow = c(3,1))
Ccf(cmort, tempr, lag = 50, main = "Mortality and Temperature")
Ccf(cmort, part, lag = 50, main = "Mortality and Pollution")
Ccf(tempr, part, lag = 50, main = "Temperature and Pollution")
# -->
library(astsa)
par(mfrow = c(3,1))
Ccf(cmort, tempr, lag = 50, main = "Mortality and Temperature")
Ccf(cmort, part, lag = 50, main = "Mortality and Pollution")
Ccf(tempr, part, lag = 50, main = "Temperature and Pollution")
library(MTS)
par(mfrow = c(3,1))
Ccf(cmort, tempr, lag = 50, main = "Mortality and Temperature")
Ccf(cmort, part, lag = 50, main = "Mortality and Pollution")
Ccf(tempr, part, lag = 50, main = "Temperature and Pollution")
library(forecast)
par(mfrow = c(3,1))
Ccf(cmort, tempr, lag = 50, main = "Mortality and Temperature")
Ccf(cmort, part, lag = 50, main = "Mortality and Pollution")
Ccf(tempr, part, lag = 50, main = "Temperature and Pollution")
graphics.off()
astsa::lag2.plot(part, cmort, max.lag = 20)
Ccf(part, cmort, lag.max = 20, plot=FALSE)
Ccf(part, cmort, lag.max = 20, plot=TRUE)
graphics.off()
astsa::lag2.plot(part, cmort, max.lag = 20)
Ccf(cmort, part, lag = 50, main = "Mortality and Pollution")
Ccf(cmort, tempr, lag = 50, main = "Mortality and Temperature")
par(mfrow = c(3,1))
Ccf(cmort, tempr, lag = 50, main = "Mortality and Temperature")
Ccf(cmort, part, lag = 50, main = "Mortality and Pollution")
Ccf(tempr, part, lag = 50, main = "Temperature and Pollution")
temp <- tempr - mean(tempr)
temp2 <- temp ^ 2
trend <- time(cmort)
part4 <- stats::lag(part, -4)
fit4 <- lm(cmort ~ trend + temp + temp2 + part, na.action = NULL)
# ----------
# including 4 weeks prior Pollution (particulate count)
# coeff for part4 will be NA
fit5 <- lm(cmort ~ trend + temp + temp2 + part + part4, na.action = NULL)
fit5 <- lm(cmort ~ trend + temp + temp2 + part4, na.action = NULL)
# ----------
summary(fit4)
summary(fit5)
# The headache of aligning the lagged series can be avoided by using dynlm
library(dynlm)
# dynlm model have time series attributes without any additional commands
# produces errors ...
fit6 <- dynlm(cmort ~ trend  + temp + temp2 + part + L(part, -4))
summary(fit6)
# ----------
plot(fit6)
library(dynlm)
fit6 <- dynlm(cmort ~ trend  + temp + temp2 + part + L(part, -4))
temp <- tempr - mean(tempr)
temp2 <- temp ^ 2
trend <- time(cmort)
part4 <- stats::lag(part, -4)
temp <- tempr - mean(tempr)
temp2 <- temp ^ 2
trend <- time(cmort)
part4 <- stats::lag(part, -4)
fit4 <- lm(cmort ~ trend + temp + temp2 + part, na.action = NULL)
fit5 <- lm(cmort ~ trend + temp + temp2 + part + part4, na.action = NULL)
fit5 <- lm(cmort ~ trend + temp + temp2 + part4, na.action = NULL)
# ----------
summary(fit4)
summary(fit5)
library(dynlm)
fit6 <- dynlm(cmort ~ trend  + temp + temp2 + part + L(part, -4))
help(dynlm)
part
trend
cmort
str(cmort)
str(cmort)
str(tempr)
str(part)
str(trend)
trend
fit6 <- dynlm(cmort ~ index(trend)  + temp + temp2 + part + L(part, -4))
summary(fit6)
fit6 <- dynlm(cmort ~ trend  + temp + temp2 + part + L(part, -4))
temp <- tempr - mean(tempr)
temp2 <- temp ^ 2
trend <- time(cmort)
# ----------
# curvilinear temperature and pollution:  Mt = beta0 + beta1 * t + beta2 * (Tt - T.) + beta3 * (Tt - T.)^2 + beta4 * Pt + wt
fit4 <- lm(cmort ~ trend + temp + temp2 + part, na.action = NULL)
# ----------
graphics.off()
par(mfrow = c(2,2))
plot(fit4)
# ----------
# check residual autocorrelation
acf2(resid(fit4), max.lag = 52)
# -->
# Indicating the residuals is modelled by AR(2)
# ----------
sarima(cmort, p = 2, d = 0, q = 0, xreg = cbind(trend, temp, temp2, part))
sarima(cmort, p = 2, d = 0, q = 0, xreg = cbind(trend, temp2, part))
library(vars)
x <- cbind(cmort, tempr, part)
# ----------
# "both" fits constant + trend
summary(VAR(x, p = 1, type = "both"))
# vars rit vector AR models via least squares.
library(vars)
x <- cbind(cmort, tempr, part)
# ----------
# "both" fits constant + trend
VARselect(x, lag.max = 10, type = "both")
summary(fit <- VAR(x, p = 2, type = "both"))
acf(resid(fit), lag.max = 52)
acf(resid(fit), 52)$acf
vars::serial.test(fit, lags.pt = 12, type = "PT.adjusted")
fit.pr <- predict(fit, n.ahead = 24, ci = 0.95)
# ----------
# plot prediction + error
plot(fit.pr)
# ----------
vars::fanchart(fit.pr)
library(marima)
model <- define.model(kvar = 3, ar = c(1,2), ma = c(1))
arp <- model$ar.pattern
map <- model$ma.pattern
# ----------
# detrend cmort
cmort.d <- resid(detr <- lm(cmort ~ time(cmort), na.action = NULL))
# strip ts attributes
xdata <- matrix(cbind(cmort.d, tempr, part), ncol = 3)
# ----------
fit <- marima(xdata, ar.pattern = arp, ma.pattern = map, means = c(0, 1, 1), penalty = 1)
# ------------------------------------------------------------------------------
# residual analysis
# ------------------------------------------------------------------------------
innov <- t(resid(fit))
plot.ts(innov)
# ----------
acf(innov, na.action = na.pass)
install.packages("marima", dep = T)
library(marima)
model <- define.model(kvar = 3, ar = c(1,2), ma = c(1))
arp <- model$ar.pattern
map <- model$ma.pattern
# ----------
# detrend cmort
cmort.d <- resid(detr <- lm(cmort ~ time(cmort), na.action = NULL))
# strip ts attributes
xdata <- matrix(cbind(cmort.d, tempr, part), ncol = 3)
# ----------
fit <- marima(xdata, ar.pattern = arp, ma.pattern = map, means = c(0, 1, 1), penalty = 1)
innov <- t(resid(fit))
plot.ts(innov)
# ----------
acf(innov, na.action = na.pass)
pred <- ts(t(fitted(fit))[,1], start = start(cmort), freq = frequency(cmort)) + detr$coef[1] + detr$coef[2] * time(cmort)
plot(pred, ylab = "Cardiovascular Mortality", lwd = 2, col = 4)
points(cmort)
par(mfrow = c(1,1))
plot(pred, ylab = "Cardiovascular Mortality", lwd = 2, col = 4)
points(cmort)
short.form(fit$ar.estimates, leading = FALSE)
short.form(fit$ar.fvalues, leading = FALSE)
short.form(fit$ma.estimates, leading = FALSE)
short.form(fit$ma.fvalues, leading = FALSE)
fit$resid.cov
cmort_d <- resid(lm(cmort ~ time(cmort)))
astsa::acf2(cmort_d, max.lag = 48)
# ----------
# Also check by sarima
fit1 <- sarima(cmort, 2, 0, 0, xreg = time(cmort))
fit1$ttable
dmort <- resid(fit1$fit)
acf(cbind(dmort, tempr, part))
# -->
# A strong correlation with temperature lagged one week, concurrent particulate level and the particulate level about one month prior (4 weeks prior)
# ----------
lag2.plot(tempr, dmort, 8)
lag2.plot(part, dmort, 8)
# -->
# From these results, we decided to fit the ARMAX model
# detrended_mortality(t) = phi1 * detrended_mortality(t-1) + phi2 * detrended_mortality(t-2) + beta1 * temperature(t-1) + beta2 * particualte + beta3 * particulate(t-4) + v(t)
trend <- time(cmort) - mean(time(cmort))
dcmort <- resid(fit2 <- lm(cmort ~ trend, na.action = NULL))
# ----------
# intercept = 88.7,  trend = -1.63
fit2
# ----------
u <- ts.intersect(dM = dcmort, dM1 = stats::lag(dcmort, -1), dM2 = stats::lag(dcmort, -2), T1 = stats::lag(tempr, -1), P = part, P4 = stats::lag(part, -4))
# ------------------------------------------------------------------------------
# Fit ARMAX model by lm() and check diagnostics
# ------------------------------------------------------------------------------
mod_lm <- lm(dM ~ ., data = u, na.action = NULL)
summary(mod_lm)
plot(mod_lm)
# Use sarima to provide a thorough anaysis of residuals
# ------------------------------------------------------------------------------
# get residula analysis as a byproduct
sarima(u[,1], 0, 0, 0, xreg = u[,2:6])
# -->
# The residual analysis supports the model
phi1 <- est$par[1]
phi2 <- est$par[2]
cR <- est$par[3]
b1 <- est$par[4]
b2 <- est$par[5]
b3 <- est$par[6]
b4 <- est$par[7]
alf <- est$par[8]
mu0 <- matrix(c(0, 0), 2, 1)
Sigma0 <- diag(100, 2)
Phi <- matrix(c(phi1, phi2, 1, 0), 2)
Theta <- matrix(c(phi1, phi2), 2)
Ups <- matrix(c(b1, 0, b2, 0, b3, 0, 0, 0, 0, 0), 2, 5)
Gam <- matrix(c(0, 0, 0, b4, alf), 1, 5)
cQ <- cR
S <- cR^2
# ----------
kf <- Kfilter2(num, y, A, mu0, Sigma0, Phi, Ups, Gam, Theta, cQ, cR, S, input)
# ----------
res <- ts(as.vector(kf$innov), start = start(cmort), freq = frequency(cmort))
sarima(res, 0, 0, 0, no.constant = TRUE)
# center time
trend <- time(cmort) - mean(time(cmort))
# appropriate time series of 1s
const <- time(cmort) / time(cmort)
# ----------
ded <- ts.intersect(M = cmort, T1 = stats::lag(tempr, -1), P = part, P4 = stats::lag(part, -4), trend, const)
y <- ded[,1]
input <- ded[,2:6]
num <- length(y)
( A <- array(c(1, 0), dim = c(1, 2, num)) )
# ----------
# Function to calculate likelihood
Linn <- function(para){
phi1 <- para[1];  phi2 <- para[2];  cR = para[3];  b1 = para[4];  b2 <- para[5];  b3 <- para[6];  b4 <- para[7];  alf <- para[8];
mu0 <- matrix(c(0, 0), 2, 1)
Sigma0 <- diag(100, 2)
Phi <- matrix(c(phi1, phi2, 1, 0), 2)
Theta <- matrix(c(phi1, phi2), 2)
Ups <- matrix(c(b1, 0, b2, 0, b3, 0, 0, 0, 0, 0), 2, 5)
Gam <- matrix(c(0, 0, 0, b4, alf), 1, 5)
cQ <- cR
S <- cR^2
kf <- Kfilter2(num, y, A, mu0, Sigma0, Phi, Ups, Gam, Theta, cQ, cR, S, input)
return(kf$like)
}
# ----------
# Estimation
# Set referring to previous modeling by lm() or sarima()
init.par <- c(phi1 = 0.3, phi2 = 0.3, cR = 5, b1 = -0.2, b2 = 0.1, b3 = 0.05, b4 = -1.6, alf = mean(cmort))
# Lower bound and upper bound on parameters used in optim
L <- c(0, 0, 1, -1, 0, 0, -2, 70)
U <- c(0.5, 0.5, 10, 0, 0.5, 0.5, 0, 90)
( est <- optim(init.par, Linn, NULL, method = "L-BFGS-B", lower = L, upper = U, hessian = TRUE, control = list(trace = 1, REPORT = 1, factr = 10^8)) )
SE <- sqrt(diag(solve(est$hessian)))
# ----------
# results
round(cbind(estimate = est$par, SE), 3)
# -->
# We notice that the value of estimated parameters are close to initial values estimated by lm() and sarima()
trend <- time(cmort) - mean(time(cmort))
# This model is different from previous model in that the mortality process is NOT detrended,
# but trend appears as an exogeneous variable
u <- ts.intersect(M = cmort, M1 = stats::lag(cmort, -1), M2 = stats::lag(cmort, -2), T1 = stats::lag(tempr, -1), P = part, P4 = stats::lag(part, -4), trend)
# ----------
sarima(u[,1], 0, 0, 0, xreg = u[,2:7])
str(cmort)
cmort
str(cmort)
str(tempr)
sarima(cmort, p = 2, d = 0, q = 0, xreg = cbind(trend, temp, temp2, part))
library(vars)
x <- cbind(cmort, tempr, part)
# ----------
# "both" fits constant + trend
summary(VAR(x, p = 1, type = "both"))
library(vars)
x <- cbind(cmort, tempr, part)
# ----------
# "both" fits constant + trend
VARselect(x, lag.max = 10, type = "both")
summary(fit <- VAR(x, p = 2, type = "both"))
VARselect(x, lag.max = 10, type = "both")
summary(fit <- VAR(x, p = 2, type = "both"))
# Acf2 can not be used for multivariate time series ...
acf(resid(fit), lag.max = 52)
acf(resid(fit), 52)$acf
vars::serial.test(fit, lags.pt = 12, type = "PT.adjusted")
cmort_d <- resid(lm(cmort ~ time(cmort)))
astsa::acf2(cmort_d, max.lag = 48)
fit1 <- sarima(cmort, 2, 0, 0, xreg = time(cmort))
fit1$ttable
dmort <- resid(fit1$fit)
acf(cbind(dmort, tempr, part))
lag2.plot(tempr, dmort, 8)
lag2.plot(part, dmort, 8)
trend <- time(cmort) - mean(time(cmort))
# This model is different from previous model in that the mortality process is NOT detrended,
# but trend appears as an exogeneous variable
u <- ts.intersect(M = cmort, M1 = stats::lag(cmort, -1), M2 = stats::lag(cmort, -2), T1 = stats::lag(tempr, -1), P = part, P4 = stats::lag(part, -4), trend)
# ----------
sarima(u[,1], 0, 0, 0, xreg = u[,2:7])
sarima(cmort, p = 2, d = 0, q = 0, xreg = cbind(trend, temp, temp2, part))
model <- define.model(kvar = 3, ar = c(1,2), ma = c(1))
arp <- model$ar.pattern
map <- model$ma.pattern
# ----------
# detrend cmort
cmort.d <- resid(detr <- lm(cmort ~ time(cmort), na.action = NULL))
# strip ts attributes
xdata <- matrix(cbind(cmort.d, tempr, part), ncol = 3)
# ----------
fit <- marima(xdata, ar.pattern = arp, ma.pattern = map, means = c(0, 1, 1), penalty = 1)
innov <- t(resid(fit))
plot.ts(innov)
# ----------
acf(innov, na.action = na.pass)
short.form(fit$ar.estimates, leading = FALSE)
short.form(fit$ar.fvalues, leading = FALSE)
short.form(fit$ma.estimates, leading = FALSE)
short.form(fit$ma.fvalues, leading = FALSE)
fit$resid.cov
# ACF and PACF for detrended cmort
cmort_d <- resid(lm(cmort ~ time(cmort)))
astsa::acf2(cmort_d, max.lag = 48)
# ----------
# Also check by sarima
fit1 <- sarima(cmort, 2, 0, 0, xreg = time(cmort))
fit1$ttable
# -->
# An AR(2) model fits well to detrended cmort
# ------------------------------------------------------------------------------
# Preliminary analysis for ARMAX model:  other variables
# ------------------------------------------------------------------------------
# CCF between the mortality residuals, the temperature series and the particulates series
dmort <- resid(fit1$fit)
acf(cbind(dmort, tempr, part))
dmort <- resid(fit1$fit)
acf(cbind(dmort, tempr, part))
lag2.plot(tempr, dmort, 8)
acf(cbind(dmort, tempr, part))
lag2.plot(tempr, dmort, 8)
lag2.plot(part, dmort, 8)
