function(x) {
tabDF <- as.data.frame(table(x$Role, x$Dept.No.))
out <- data.frame(t(tabDF$Freq))
names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
out
},
.parallel = cores > 1)
names(investDept) <- shortNames(names(investDept))
investDept <- noZV(investDept)
head(investDept)
# ----------
# Create variables for each role/faculty
investFaculty <- ddply(vertical, .(Grant.Application.ID),
function(x) {
tabDF <- as.data.frame(table(x$Role, x$Faculty.No.))
out <- data.frame(t(tabDF$Freq))
names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
out
},
.parallel = cores > 1)
names(investFaculty) <- shortNames(names(investFaculty))
investFaculty <- noZV(investFaculty)
head(investFaculty)
# ----------
# Create dummy variables for each tenure length
investDuration <- ddply(vertical, .(Grant.Application.ID),
function(x) as.data.frame(t(as.matrix(table(x$No..of.Years.in.Uni.at.Time.of.Grant)))),
.parallel = cores > 1)
investDuration[is.na(investDuration)] <- 0
head(investDuration)
# ----------
# Create variables for the number of publications per journal type. Note that we also compute the total number, which should be
# removed for models that cannot deal with such a linear dependency
totalPub <- ddply(vertical, .(Grant.Application.ID),
function(x) {
data.frame(AstarTotal = sum(x$A., na.rm = TRUE),
ATotal = sum(x$A, na.rm = TRUE),
BTotal = sum(x$B, na.rm = TRUE),
CTotal = sum(x$C, na.rm = TRUE),
allPub = sum(c(x$A., x$A, x$B, x$C), na.rm = TRUE))
},
.parallel = cores > 1)
head(totalPub)
# ----------
# Create variables for the number of publications per journal type per role.
investPub <- ddply(vertical, .(Grant.Application.ID, Role),
function(x) {
data.frame(Astar = sum(x$A., na.rm = TRUE),
A = sum(x$A, na.rm = TRUE),
B = sum(x$B, na.rm = TRUE),
C = sum(x$C, na.rm = TRUE))
},
.parallel = cores > 1)
investPub <- reshape(investPub, direction = "wide", idvar = "Grant.Application.ID", timevar = "Role")
investPub[is.na(investPub)] <- 0
names(investPub) <- shortNames(names(investPub))
investPub <- noZV(investPub)
head(investPub)
# ----------
# Create variables for each RFCD code
RFCDcount <- ddply(vertical, .(Grant.Application.ID),
function(x) as.data.frame(t(as.matrix(table(x$RFCD.Code)))),
.parallel = cores > 1)
RFCDcount <- noZV(RFCDcount)
head(RFCDcount)
# ----------
# Create variables for each SEO code
SEOcount <- ddply(vertical, .(Grant.Application.ID),
function(x) as.data.frame(t(as.matrix(table(x$SEO.Code)))),
.parallel = cores > 1)
SEOcount <- noZV(SEOcount)
head(SEOcount)
# ----------
# Make dummy vars out of grant-specific data
grantData <- raw[, c("Sponsor.Code", "Contract.Value.Band...see.note.A", "Grant.Category.Code")]
# Make a lubridate object for the time, then derive the day, week and month info
startTime <- dmy(raw$Start.date)
grantData$Month <- factor(as.character(month(startTime, label = TRUE)))
grantData$Weekday <- factor(as.character(wday(startTime, label = TRUE)))
grantData$Day <- day(startTime)
grantData$Yday <- yday(startTime)
grantYear <- year(startTime)
# ----------
# Use the dummyVars function to create binary variables for grant-specific variables
dummies <- dummyVars(~., data = grantData, levelsOnly = TRUE)
grantData <- as.data.frame(predict(dummies, grantData))
names(grantData) <- gsub(" ", "", names(grantData))
grantData$Grant.Application.ID <- raw$Grant.Application.ID
grantData$Class <- factor(ifelse(raw$Grant.Status, "successful", "unsuccessful"))
grantData$Grant.Application.ID <- raw$Grant.Application.ID
grantData$is2008 <- year(startTime) == 2008
grantData <- noZV(grantData)
# ----------
# Merge all the predictors together, remove zero variance columns and merge in the outcome data
summarized <- merge(investCount, investDOB)
summarized <- merge(summarized, investCountry)
summarized <- merge(summarized, investLang)
summarized <- merge(summarized, investPhD)
summarized <- merge(summarized, investGrants)
summarized <- merge(summarized, investDept)
summarized <- merge(summarized, investFaculty)
summarized <- merge(summarized, investDuration)
summarized <- merge(summarized, investPub)
summarized <- merge(summarized, totalPub)
summarized <- merge(summarized, people)
summarized <- merge(summarized, RFCDcount)
summarized <- merge(summarized, SEOcount)
summarized <- merge(summarized, grantData)
# Remove the ID column
summarized$Grant.Application.ID <- NULL
print(str(summarized))
# ------------------------------------------------------------------------------
# split training and test data
# ------------------------------------------------------------------------------
# We'll split all of the pre-2008 data into the training set and a portion of the 2008 data too
training <- subset(summarized, !is2008)
pre2008 <- 1:nrow(training)
year2008 <- subset(summarized, is2008)
# ----------
# Now randomly select some 2008 data for model training and add it back into the existing training data
set.seed(568)
inTrain <- createDataPartition(year2008$Class, p = 3/4)[[1]]
training2 <- year2008[ inTrain,]
testing   <- year2008[-inTrain,]
training <- rbind(training, training2)
training$is2008 <- testing$is2008 <- NULL
training <- noZV(training)
testing <- testing[, names(training)]
# ------------------------------------------------------------------------------
# Create fullset and reduced set
# ------------------------------------------------------------------------------
# Create two character vectors for different predictor sets. One will have all the predictors (called 'fullSet').
# Another has some of the sparse predictors removed for models that require such filtering. This will be called 'reducedSet'
# (predictors without sparse or Near Zero Variance predictors). This set will also have predictors removed that are almost completely
# correlated with other predictors
fullSet <- names(training)[names(training) != "Class"]
predCorr <- cor(training[,fullSet])
highCorr <- findCorrelation(predCorr, .99)
fullSet <- fullSet[-highCorr]
isNZV <- nearZeroVar(training[,fullSet], saveMetrics = TRUE, freqCut = floor(nrow(training)/5))
fullSet <-  rownames(subset(isNZV, !nzv))
str(fullSet)
reducedSet <- rownames(subset(isNZV, !nzv & freqRatio < floor(nrow(training)/50)))
# ----------
# Perfectly collinear predictors (due to their construction) March and Sunday were selected because they have the lowest frequency of all months and days
reducedSet <- reducedSet[(reducedSet != "allPub") &
(reducedSet != "numPeople") &
(reducedSet != "Mar") &
(reducedSet != "Sun")
]
# all months and days
reducedSet <- reducedSet[(reducedSet != "allPub") &
(reducedSet != "numPeople") &
(reducedSet != "Mar") &
(reducedSet != "Sun")
]
str(reducedSet)
# ----------
length(fullSet)
length(reducedSet)
# ------------------------------------------------------------------------------
# Save data
# ------------------------------------------------------------------------------
save(training, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/training")
save(testing, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/testing")
save(fullSet, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/fullSet")
save(reducedSet, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/reducedSet")
save(pre2008, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/pre2008")
rm(list=ls())
setwd("//media//kswada//MyFiles//R//kaggle_grant_applications")
packages <- c("plyr", "dplyr", "caret", "reshape2")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
# ----------
library(doMC)
cores <- 20
registerDoMC(cores)
# ----------
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/training")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/testing")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/fullSet")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/reducedSet")
load(file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/pre2008")
unique(training$Yday)
modelFit <- glm(Class ~ Yday, data = training[pre2008,], family = binomial)
summary(modelFit)
# ----------
dataGrid <- data.frame(Yday = seq(0, 365, length = 500))
dataGrid$Linear <- 1 - predict(modelFit, dataGrid, type = "response")
linear2008 <- auc(roc(response = training[-pre2008, "Class"],
predictor = 1 - predict(modelFit, training[-pre2008,], type = "response"),
levels = rev(levels(training[-pre2008, "Class"]))))
# ----------
# Class ~ Day^2
modelFit2 <- glm(Class ~ Yday + I(Yday^2), data = training[pre2008,], family = binomial)
summary(modelFit2)
# ----------
dataGrid$Quadratic <- 1 - predict(modelFit2, dataGrid, type = "response")
quad2008 <- auc(roc(response = training[-pre2008, "Class"],
predictor = 1 - predict(modelFit2, training[-pre2008,], type = "response"),
levels = rev(levels(training[-pre2008, "Class"]))))
# ----------
dataGrid <- melt(dataGrid, id.vars = "Yday")
byDay <- training[pre2008, c("Yday", "Class")]
byDay$Binned <- cut(byDay$Yday, seq(0, 360, by = 5))
observedProps <- ddply(byDay, .(Binned), function(x) c(n = nrow(x), mean = mean(x$Class == "successful")))
observedProps$midpoint <- seq(2.5, 357.5, by = 5)
# ----------
# xyplot with line + xyplot with scatter point
xyplot(value ~ Yday | variable, data = dataGrid,
ylab = "Probability of A Successful Grant",
ylim = extendrange(0:1),
between = list(x = 1),
panel = function(...)
{
panel.xyplot(x = observedProps$midpoint, observedProps$mean,
pch = 16., col = rgb(.2, .2, .2, .5))
panel.xyplot(..., type = "l", col = "black", lwd = 2)
})
# ------------------------------------------------------------------------------
training$Yday2 <- training$Yday^2
testing$Yday2 <- testing$Yday^2
fullSet <- c(fullSet, "Yday2")
reducedSet <- c(reducedSet, "Yday2")
save(training, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/training")
save(testing, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/testing")
save(fullSet, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/fullSet")
save(reducedSet, file = "/media/kswada/MyFiles/data/kaggle_grant_applications/mart_engineered/reducedSet")
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
index = list(TrainSet = pre2008),
savePredictions = TRUE)
set.seed(476)
lrFit_red <- train(x = training[, reducedSet], y = training$Class[pre2008], method = "glm", metric = "ROC", trControl = ctrl)
set.seed(476)
lrFit_red <- train(x = training[, reducedSet], y = training$Class, method = "glm", metric = "ROC", trControl = ctrl)
set.seed(476)
lrFit_full <- train(x = training[, fullSet], y = training$Class, method = "glm", metric = "ROC", trControl = ctrl)
nrow(trainin)
nrow(training)
summary(lrFit_red)
names(lrFit_red)
lrFit_red$trainingData
lrFit_red$resample
lrFit_red$results
confusionMatrix(lrFit_red, norm = "none")
confusionMatrix(lrFit_red, norm = "none")
confusionMatrix(lrFit_full, norm = "none")
+439+131+236+751
+443+127+241+746
lrFit_red$pred <- merge(lrFit_red$pred,  lrFit_red$bestTune)
lrFit_full$pred <- merge(lrFit_full$pred,  lrFit_full$bestTune)
lr_red_roc <- roc(response = lrFit_red$pred$obs, predictor = lrFit_red$pred$successful, levels = rev(levels(lrFit_red$pred$obs)))
lr_full_roc <- roc(response = lrFit_full$pred$obs, predictor = lrFit_full$pred$successful, levels = rev(levels(lrFit_full$pred$obs)))
plot(lr_red_roc, legacy.axes = TRUE, col = "blue")
plot(lr_full_roc, legacy.axes = TRUE, add = TRUE, col = "red")
auc(lr_red_roc);  auc(lr_full_roc);
ci(lr_red_roc);  ci(lr_full_roc);
dim(training)
dim(training[,reducedSet])
confusionMatrix(lrFit_red, norm = "none")
plot(varImp(lrFit_red, scale = FALSE), top = 20)
dim(training[-p322008])
dim(training[-pre2008])
dim(training[pre2008])
dim(training[pre2008,])
nrow(training)
length(pre2008)
pre2008
nrow(training[-pre2008])
nrow(training[pre2008])
nrow(training[pre2008,])
nrow(training[-pre2008,])
lr_holdout_pred <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
head(lr_holdout_pred, 20)
lr_holdout_pred$posterior
lr_red_ho_roc <- roc(response = training[-pre2008, "Class"], predictor = lr_holdout_pred[,"successful"], levels = rev(levels(training$Class)))
lr_ho_pred <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
head(lr_ho_pred, 20)
lr_red_ho_roc <- roc(response = training[-pre2008, "Class"], predictor = lr_ho_pred[,"successful"], levels = rev(levels(training$Class)))
plot(lr_red_roc, legacy.axes = TRUE, col = "blue")
plot(lr_red_ho_roc, legacy.axes = TRUE, add = TRUE, col = "red")
plot(lr_full_roc, legacy.axes = TRUE, col = "darkgray")
plot(lr_red_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
plot(lr_red_ho_roc, legacy.axes = TRUE, add = TRUE, col = "red")
auc(lr_red_roc);  auc(lr_red_ho_roc)
auc(lr_red_roc)
auc(lr_red_ho_roc)
testRes <- data.frame(obs = training[-pre2008, "Class"])
lr_ho_pred_prob <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
lr_ho_pred <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="response")
lr_ho_pred_prob
lr_ho_pred
lr_ho_pred <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="class")
lr_ho_pred <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="raw")
lr_ho_pred
lr_red_ho_pred_prob <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
lr_red_ho_pred <- predict(lrFit_red, newdata = training[-pre2008, reducedSet], type ="raw")
head(lr_red_ho_pred_prob, 20)
lr_red_ho_roc <- roc(response = training[-pre2008, "Class"], predictor = lr_red_ho_pred_prob[,"successful"], levels = rev(levels(training$Class)))
plot(lr_full_roc, legacy.axes = TRUE, col = "darkgray")
plot(lr_red_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
plot(lr_red_ho_roc, legacy.axes = TRUE, add = TRUE, col = "red")
auc(lr_red_roc)
auc(lr_red_ho_roc)
histogram( ~ lr_red_ho_pred_prob | lr_red_ho_pred, data = testRes_lr,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
testRes_lr <- data.frame(obs = training[-pre2008, "Class"], lr_red_ho_pred_prob = lr_red_ho_pred_prob["successful"], lr_red_ho_pred = lr_red_ho_pred)
# Plot the probability of successful
histogram( ~ lr_red_ho_pred_prob | lr_red_ho_pred, data = testRes_lr,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
testRes_lr
histogram( ~ lr_red_ho_pred_prob | obs, data = testRes_lr,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ lr_red_ho_pred_prob | obs, data = testRes_lr)
str(testRes_lr)
lr_red_ho_pred_prob = lr_red_ho_pred_prob["successful"]
lr_red_ho_pred
testRes_lr <- data.frame(obs = training[-pre2008, "Class"], lr_red_ho_pred_prob = lr_red_ho_pred_prob["successful"], lr_red_ho_pred = lr_red_ho_pred)
head(testRes_lr)
testRes_lr <- data.frame(obs = training[-pre2008, "Class"], lr_red_ho_pred_prob = lr_red_ho_pred_prob$successful, lr_red_ho_pred = lr_red_ho_pred)
# Plot the probability of successful
histogram( ~ lr_red_ho_pred_prob | obs, data = testRes_lr)
histogram( ~ lr_red_ho_pred_prob | obs, data = testRes_lr,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
ldaFit <- train(x = training[, reducedSet], y = training$Class, method = "lda", preProc = c("center","scale"), metric = "ROC", trControl = ctrl)
ldaFit
confusionMatrix(ldaFit, norm = "none")
ldaFit$pred <- merge(ldaFit$pred,  ldaFit$bestTune)
lda_roc <- roc(response = ldaFit$pred$obs, predictor = ldaFit$pred$successful, levels = rev(levels(ldaFit$pred$obs)))
plot(lr_red_roc, legacy.axes = TRUE, col = "blue")
plot(lda_roc, legacy.axes = TRUE, add = TRUE, col = "red")
plot(lr_red_roc, legacy.axes = TRUE, col = "darkgray")
plot(lda_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
auc(lr_red_roc);  auc(lda_roc);
ci(lr_red_roc);  ci(lda_roc);
grantPreProcess <- preProcess(training[pre2008, reducedSet])
grantPreProcess
scaledPre2008 <- predict(grantPreProcess, newdata = training[pre2008, reducedSet])
scaled2008HoldOut <- predict(grantPreProcess, newdata = training[-pre2008, reducedSet])
# ----------
ldaModel <- lda(x = scaledPre2008, grouping = training$Class[pre2008])
# ----------
# discriminant values by each class
plot(ldaModel)
head(ldaModel$scaling, 20)
tail(ldaModel$scaling, 20)
rn <- row.names(ldaModel$scaling)
ldaCoef <- data.frame(var = rn, ldacoef = abs(unname(ldaModel$scaling))) %>% arrange(desc(ldacoef))
head(ldaCoef, 20)
lda_ho_pred_prob <- predict(ldaFit, newdata = training[-pre2008, reducedSet], type ="prob")
lda_ho_pred_prob <- predict(ldaFit, newdata = training[-pre2008, reducedSet], type ="prob")
lda_ho_pred <- predict(ldaFit, newdata = training[-pre2008, reducedSet], type ="raw")
head(lda_ho_pred_prob, 20)
lda_ho_roc <- roc(response = training[-pre2008, "Class"], predictor = lda_ho_pred_prob[,"successful"], levels = rev(levels(training$Class)))
plot(lr_red_ho_roc, legacy.axes = TRUE, col = "darkgray")
plot(lda_ho_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
auc(lda_ho_roc)
auc(lr_red_ho_roc)
auc(lda_ho_roc)
testRes_lda <- data.frame(obs = training[-pre2008, "Class"], lda_ho_pred_prob = lda_ho_pred_prob$successful, lda_ho_pred = lda_ho_pred)
histogram( ~ lda_ho_pred_prob | obs, data = testRes_lda,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ lr_red_ho_pred_prob | obs, data = testRes_lr,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ lda_ho_pred_prob | obs, data = testRes_lda,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ lr_red_ho_pred_prob | obs, data = testRes_lr,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ lda_ho_pred_prob | obs, data = testRes_lda,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
nrow(training) / length(reducedSet)
set.seed(476)
plsFit_full <- train(x = training[,fullSet], y = training$Class, method = "pls", tuneGrid = expand.grid(ncomp = 1:10),
preProc = c("center","scale"), metric = "ROC", probMethod = "Bayes", trControl = ctrl)
plsFit
set.seed(476)
plsFit_full <- train(x = training[,fullSet], y = training$Class, method = "pls", tuneGrid = expand.grid(ncomp = 1:10),
preProc = c("center","scale"), metric = "ROC", probMethod = "Bayes", trControl = ctrl)
plsFit
set.seed(476)
plsFit_red <- train(x = training[,reducedSet], y = training$Class, method = "pls", tuneGrid = expand.grid(ncomp = 1:10),
preProc = c("center","scale"), metric = "ROC", probMethod = "Bayes", trControl = ctrl)
plsFit_full
plsFit_red
confusionMatrix(plsFit_full, norm = "none")
confusionMatrix(plsFit_red, norm = "none")
plsFit_full$pred <- merge(plsFit_full$pred,  plsFit_full$bestTune)
plsFit_red$pred <- merge(plsFit_red$pred,  plsFit_red$bestTune)
plsFit_full$pred <- merge(plsFit_full$pred,  plsFit_full$bestTune)
plsFit_red$pred <- merge(plsFit_red$pred,  plsFit_red$bestTune)
pls_full_roc <- roc(response = plsFit_full$pred$obs, predictor = plsFit_full$pred$successful, levels = rev(levels(plsFit_full$pred$obs)))
pls_red_roc <- roc(response = plsFit_red$pred$obs, predictor = plsFit_red$pred$successful, levels = rev(levels(plsFit_red$pred$obs)))
plsFit_full$pred <- merge(plsFit_full$pred,  plsFit_full$bestTune)
plsFit_red$pred <- merge(plsFit_red$pred,  plsFit_red$bestTune)
pls_full_roc <- roc(response = plsFit_full$pred$obs, predictor = plsFit_full$pred$successful, levels = rev(levels(plsFit_full$pred$obs)))
pls_red_roc <- roc(response = plsFit_red$pred$obs, predictor = plsFit_red$pred$successful, levels = rev(levels(plsFit_red$pred$obs)))
plot(lda_roc, legacy.axes = TRUE, col = "darkgray")
plot(pls_full_roc, legacy.axes = TRUE, add = TRUE, col = "red")
plot(pls_red_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
auc(lda_roc);  auc(pls_full_roc);  auc(pls_red_roc);
ci(lda_roc);  ci(pls_full_roc);  ci(pls_red_roc);
confusionMatrix(plsFit_red, norm = "none")
auc(lda_roc);  auc(pls_full_roc);  auc(pls_red_roc);
plot(plsFit_full)
plot(plsFit_red)
plot(lr_red_roc, type = "s", col = rgb(.2, .2, .2, .2), add = TRUE, legacy.axes = TRUE, col = "darkgray")
plot(lda_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE, col = "black")
plot(pls_full_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "red")
plot(pls_full_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "blue")
plot(lr_red_roc, type = "s", col = rgb(.2, .2, .2, .2), add = TRUE, legacy.axes = TRUE)
lr_red_roc
lda_roc
lr_red_roc
plot(lr_red_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE)
plot(lda_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE, add = TRUE, col = "black")
plot(lda_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE, add = TRUE)
plot(lr_red_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE)
plot(lda_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE, add = TRUE)
plot(pls_full_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "red")
plot(pls_full_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "blue")
plot(lr_red_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE)
plot(lda_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE, add = TRUE)
plot(pls_full_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "blue")
plot(pls_red_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "red")
plsFit_full$results
best(plsFit_full$results, "ROC", maximize = TRUE)
plsFit_full$results[best(plsFit_full$results, "ROC", maximize = TRUE), "ncomp"]
plot(varImp(plsFit_full, scale = FALSE), top=20, scales = list(y = list(cex = .95)))
ldaModel <- caret::plsda(x = training[pre2008, reducedSet], y = training[pre2008, "Class"], scale = TRUE,
probMethod = "Bayes", probMethod = "Bayes", ncomp = 6)
help(plsda)
ldaModel <- caret::plsda(x = training[pre2008, reducedSet], y = training[pre2008, "Class"], scale = TRUE,
probMethod = "Bayes", ncomp = 6)
plsdaModel <- caret::plsda(x = training[pre2008, reducedSet], y = training[pre2008, "Class"], scale = TRUE,
probMethod = "Bayes", ncomp = 6)
plot(plsdaModel)
scoreplot(plsdaModel)
loadings(plsdaModel)
names(plsdaModel)
plsda_ho_pred_prob <- predict(plsdaFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
plsda_ho_pred <- predict(plsdaFit_red, newdata = training[-pre2008, reducedSet], type ="raw")
pls_ho_pred_prob <- predict(plsFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
pls_ho_pred <- predict(plsFit_red, newdata = training[-pre2008, reducedSet], type ="raw")
head(pls_ho_pred_prob, 20)
nrow(training[-pre2008,])
pls_red_ho_pred_prob <- predict(plsFit_red, newdata = training[-pre2008, reducedSet], type ="prob")
pls_red_ho_pred <- predict(plsFit_red, newdata = training[-pre2008, reducedSet], type ="raw")
head(pls_red_ho_pred_prob, 20)
pls_red_ho_roc <- roc(response = training[-pre2008, "Class"], predictor = pls_red_ho_pred_prob[,"successful"], levels = rev(levels(training$Class)))
plot(lda_ho_roc, legacy.axes = TRUE, col = "darkgray")
plot(pls_red_ho_roc, legacy.axes = TRUE, add = TRUE, col = "blue")
auc(lda_ho_roc)
auc(pls_red_ho_roc)
testRes_pls <- data.frame(obs = training[-pre2008, "Class"], pls_red_ho_pred_prob = pls_red_ho_pred_prob$successful, pls_red_ho_pred = pls_red_ho_pred)
histogram( ~ lda_ho_pred_prob | obs, data = testRes_lda,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ pls_red_ho_pred_prob | obs, data = testRes_pls,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ pls_red_ho_pred_prob | obs, data = testRes_pls,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ lda_ho_pred_prob | obs, data = testRes_lda,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
histogram( ~ pls_red_ho_pred_prob | obs, data = testRes_pls,
layout = c(2, 1), nint = 20, xlab = "Probability of Successful Applicationos", type = "count")
glmnGrid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1), lambda = seq(.01, .2, length = 40))
set.seed(476)
# full set
glmnFit <- train(x = training[,fullSet], y = training$Class, method = "glmnet",
tuneGrid = glmnGrid, preProc = c("center", "scale"), metric = "ROC", trControl = ctrl)
glmnFit
glmnFit
plot(glmnFit)
glmnGrid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1), lambda = seq(.01, .3, length = 80))
set.seed(476)
# Fit by full set data
glmnFit <- train(x = training[,fullSet], y = training$Class, method = "glmnet",
tuneGrid = glmnGrid, preProc = c("center", "scale"), metric = "ROC", trControl = ctrl)
plot(glmnFit)
summary(glmnFit)
confusionMatrix(glmnFit, norm = "none")
glmnFit$pred <- merge(glmnFit$pred,  glmnFit$bestTune)
glmn_roc <- roc(response = glmnFit$pred$obs, predictor = glmnFit$pred$successful, levels = rev(levels(glmnFit$pred$obs)))
plot(lr_red_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE)
plot(lda_roc, type = "s", col = rgb(.2, .2, .2, .2), legacy.axes = TRUE, add = TRUE)
plot(pls_red_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "red")
plot(glmn_roc, type = "s", add = TRUE, legacy.axes = TRUE, col = "blue")
auc(lda_roc);  auc(pls_red_roc);  auc(glmn_roc);
ci(lda_roc);  ci(pls_red_roc);  ci(glmn_red_roc);
ci(lda_roc);  ci(pls_red_roc);  ci(glmn_roc);
plot(varImp(glmnFit, scale = FALSE), top=20, scales = list(y = list(cex = .95)))
glmnFit0 <- glmnFit
glmnFit0$results$lambda <- format(round(glmnFit0$results$lambda, 3))
glmnPlot <- plot(glmnFit0, plotType = "level", cuts = 15, scales = list(x = list(rot = 90, cex = .65)))
plot(glmnFit0, plotType = "level", cuts = 15, scales = list(x = list(rot = 90, cex = .65)))
plot(glmnFit0, plotType = "level", cuts = 15, scales = list(x = list(rot = 90, cex = .65)))
glmnPlot <- plot(glmnFit0, plotType = "level", cuts = 15, scales = list(x = list(rot = 90, cex = .65)))
update(glmnPlot,
ylab = "Mixing Percentage\nRidge <---------> Lasso",
sub = "",
main = "Area Under the ROC Curve",
xlab = "Amount of Regularization")
glmnFit
glmnFit
plot(glmnFit)
names(glmnFit)
glmnFit$fianlModel
glmnFit$finallModel
glmnFit$finalModel
names(glmnFit)
glmnFit$modelInfo
packages <- c("dplyr", "caret", "glmnet")
